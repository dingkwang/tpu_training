{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[],"dockerImageVersionId":31235,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MBPP+ GRPO Training - All in One Notebook\nComplete pipeline for training Gemma-3-1B on MBPP+ code generation using GRPO.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Install Dependencies","metadata":{}},{"cell_type":"code","source":"%%time\nprint(\"Installing dependencies...\")\n\n!pip install -q datasets huggingface_hub\n!pip install -q -U \"google-tunix[prod]\"\nprint(\"✓ All dependencies installed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:05:57.525673Z","iopub.execute_input":"2025-12-26T01:05:57.525867Z","iopub.status.idle":"2025-12-26T01:06:11.616811Z","shell.execute_reply.started":"2025-12-26T01:05:57.525844Z","shell.execute_reply":"2025-12-26T01:06:11.615426Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n✓ All dependencies installed\nCPU times: user 96.5 ms, sys: 37.4 ms, total: 134 ms\nWall time: 14.1 s\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip uninstall -y datasets pyarrow\n!pip install uv\n!uv cache clean datasets pyarrow\n!uv pip install --system --reinstall --no-cache-dir \"datasets\"\n\nimport sys, datasets\nprint(\"python\", sys.version)\nprint(\"executable\", sys.executable)\nprint(\"datasets\", datasets.__version__)\nfrom datasets import load_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:25:23.206000Z","iopub.execute_input":"2025-12-26T01:25:23.206137Z","iopub.status.idle":"2025-12-26T01:25:44.069514Z","shell.execute_reply.started":"2025-12-26T01:25:23.206120Z","shell.execute_reply":"2025-12-26T01:25:44.068583Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: datasets 2.14.4\nUninstalling datasets-2.14.4:\n  Successfully uninstalled datasets-2.14.4\nFound existing installation: pyarrow 22.0.0\nUninstalling pyarrow-22.0.0:\n  Successfully uninstalled pyarrow-22.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0mCollecting uv\n  Downloading uv-0.9.18-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nDownloading uv-0.9.18-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: uv\nSuccessfully installed uv-0.9.18\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNo cache found at: \u001b[36m/root/.cache/uv\u001b[39m\n\u001b[2mUsing Python 3.12.12 environment at: /usr/local\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m39 packages\u001b[0m \u001b[2min 418ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m39 packages\u001b[0m \u001b[2min 1.01s\u001b[0m\u001b[0m                                            \n\u001b[2mUninstalled \u001b[1m34 packages\u001b[0m \u001b[2min 318ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m39 packages\u001b[0m \u001b[2min 88ms\u001b[0m\u001b[0m                               \u001b[0m\n \u001b[33m~\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.13.2\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.4.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.3.7\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.1\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.8.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.1rc0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.7.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.15\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.18\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0rc1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==3.0.0rc0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.4.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.3\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.2\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.6.0\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.22.0\u001b[0m\npython 3.12.12 (main, Dec  9 2025, 02:04:51) [GCC 14.2.0]\nexecutable /usr/local/bin/python\ndatasets 4.4.2\npyarrow 22.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Step 2: Configuration","metadata":{}},{"cell_type":"code","source":"# Model configuration\nMODEL_ID = \"google/gemma-3-1b-it\"\nTOKENIZER_PATH = \"gs://gemma-data/tokenizers/tokenizer_gemma3.model\"\nMAX_SEQ_LEN = 1024\n\n\n# Training configuration\nLEARNING_RATE = 3e-6\nNUM_GENERATIONS = 2\nTEMPERATURE = 0.9\nTOP_K = 50\nTOP_P = 1.0\nBETA = 0.08\nEPSILON = 0.2\nNUM_ITERATIONS = 1\nTOTAL_GENERATION_STEPS = 768\nMAX_PROMPT_LENGTH = 256\n\nprint(\"✓ Configuration loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:32:31.270821Z","iopub.execute_input":"2025-12-26T01:32:31.271076Z","iopub.status.idle":"2025-12-26T01:32:31.275439Z","shell.execute_reply.started":"2025-12-26T01:32:31.271055Z","shell.execute_reply":"2025-12-26T01:32:31.274535Z"}},"outputs":[{"name":"stdout","text":"✓ Configuration loaded\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Step 3: Define Helper Functions","metadata":{}},{"cell_type":"code","source":"import re\nimport subprocess\nfrom typing import List\n\n# ============================================================================\n# Reward Functions\n# ============================================================================\n\ndef extract_code(completion: str) -> str | None:\n    \"\"\"Extract Python code from model completion.\"\"\"\n    # Try ```python ... ```\n    python_block = re.search(r'```python\\s*\\n(.*?)\\n```', completion, re.DOTALL)\n    if python_block:\n        return python_block.group(1).strip()\n    \n    # Try ``` ... ```\n    generic_block = re.search(r'```\\s*\\n(.*?)\\n```', completion, re.DOTALL)\n    if generic_block:\n        return generic_block.group(1).strip()\n    \n    # Look for function definition\n    if 'def ' in completion:\n        def_start = completion.find('def ')\n        if def_start != -1:\n            return completion[def_start:].strip()\n    \n    return None\n\ndef has_code_block(completion: str) -> bool:\n    \"\"\"Check if completion contains a code block.\"\"\"\n    return bool(re.search(r'```(?:python)?\\s*\\n.*?\\n```', completion, re.DOTALL))\n\ndef execute_test(code: str, test: str, test_imports, timeout: float = 3.0) -> tuple[int, int]:\n    \"\"\"Execute MBPP+ tests on generated code.\"\"\"\n    try:\n        script_parts = []\n        \n        # Add imports\n        if test_imports:\n            if isinstance(test_imports, str):\n                if test_imports.strip():\n                    script_parts.append(test_imports)\n            else:\n                for imp in test_imports:\n                    script_parts.append(imp)\n        \n        # Add code and test\n        script_parts.append(code)\n        script_parts.append(test)\n        full_script = '\\n'.join(script_parts)\n        \n        # Execute\n        result = subprocess.run(\n            [\"python3\", \"-c\", full_script],\n            timeout=timeout,\n            capture_output=True,\n            text=True\n        )\n        \n        test_count = test.count('assert')\n        if result.returncode == 0:\n            return (test_count, test_count)\n        else:\n            return (0, test_count if test_count > 0 else 1)\n    \n    except subprocess.TimeoutExpired:\n        test_count = test.count('assert')\n        return (0, test_count if test_count > 0 else 1)\n    except Exception:\n        test_count = test.count('assert') if test else 1\n        return (0, test_count if test_count > 0 else 1)\n\ndef mbppplus_verifier_reward(prompts: List[str], completions: List[str],\n                              test, test_imports=None, **kwargs) -> List[float]:\n    \"\"\"Main MBPP+ reward: test pass rate.\"\"\"\n    rewards = []\n    \n    # Handle test and test_imports batching\n    if isinstance(test, str):\n        tests = [test] * len(completions)\n    else:\n        try:\n            test_list = list(test)\n            if len(test_list) == len(completions):\n                tests = test_list\n            else:\n                tests = test_list * len(completions) if len(test_list) > 0 else [test_list[0]] * len(completions)\n        except:\n            tests = [test] * len(completions)\n    \n    if test_imports is None:\n        imports_list = [None] * len(completions)\n    elif isinstance(test_imports, str):\n        imports_list = [test_imports] * len(completions)\n    else:\n        try:\n            test_imports_list = list(test_imports)\n            if len(test_imports_list) == len(completions):\n                imports_list = test_imports_list\n            else:\n                imports_list = [test_imports_list] * len(completions)\n        except:\n            imports_list = [test_imports] * len(completions)\n    \n    # Evaluate each completion\n    for i, completion in enumerate(completions):\n        code = extract_code(completion)\n        if code is None:\n            rewards.append(0.0)\n            continue\n        \n        try:\n            passed, total = execute_test(code, tests[i], imports_list[i], timeout=3.0)\n            reward = passed / total if total > 0 else 0.0\n            rewards.append(reward)\n        except Exception:\n            rewards.append(0.0)\n    \n    return rewards\n\ndef code_format_reward(prompts: List[str], completions: List[str], **kwargs) -> List[float]:\n    \"\"\"Format reward: encourage code blocks.\"\"\"\n    return [0.5 if has_code_block(c) else -0.2 for c in completions]\n\nDEFAULT_REWARD_FNS_MBPP = [\n    mbppplus_verifier_reward,\n    code_format_reward,\n]\n\nprint(\"✓ Reward functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:32:33.680184Z","iopub.execute_input":"2025-12-26T01:32:33.680444Z","iopub.status.idle":"2025-12-26T01:32:33.691611Z","shell.execute_reply.started":"2025-12-26T01:32:33.680413Z","shell.execute_reply":"2025-12-26T01:32:33.690812Z"}},"outputs":[{"name":"stdout","text":"✓ Reward functions defined\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Step 4: Data Loader Function","metadata":{}},{"cell_type":"code","source":"import grain.python as grain\nimport pyarrow\nimport pyarrow.parquet as pq\nimport numpy as np\n\ndef get_mbpp_dataset(\n    local_path=\"./data/mbppplus_hf\",\n    train_fraction=0.9,\n    batch_size=1,\n    num_train_batches=None,\n    num_test_batches=64,\n    num_epochs=1,\n    shuffle=True,\n    seed=42,\n):\n    \"\"\"Load MBPP+ dataset using grain.\"\"\"\n    import glob\n    \n    # Load parquet\n    parquet_files = glob.glob(f\"{local_path}/*.parquet\")\n    if not parquet_files:\n        raise FileNotFoundError(f\"No parquet files found in {local_path}\")\n    \n    table = pq.read_table(parquet_files[0])\n    dataset = table.to_pylist()\n    \n    # Format prompts\n    for item in dataset:\n        item['prompts'] = f\"\"\"# Problem: {item['prompt']}\n# Write a Python function to solve this problem.\n# Return only Python code in a ```python ... ``` block.\n\n\"\"\"\n        # Convert test_imports list to string\n        if 'test_imports' in item and item['test_imports']:\n            if isinstance(item['test_imports'], list):\n                item['test_imports'] = '\\n'.join(item['test_imports'])\n    \n    # Split dataset\n    total_samples = len(dataset)\n    train_size = int(total_samples * train_fraction)\n    \n    if shuffle:\n        np.random.seed(seed)\n        indices = np.random.permutation(total_samples)\n        dataset = [dataset[i] for i in indices]\n    \n    train_data = dataset[:train_size]\n    test_data = dataset[train_size:] if train_size < total_samples else dataset[-2:]\n    \n    # Create grain datasets\n    train_source = grain.MapDataset.source(train_data)\n    test_source = grain.MapDataset.source(test_data)\n    \n    # Apply transformations\n    train_ds = train_source.batch(batch_size=batch_size)\n    test_ds = test_source.batch(batch_size=batch_size)\n    \n    if num_train_batches:\n        train_ds = train_ds[:num_train_batches]\n    if num_test_batches:\n        test_ds = test_ds[:num_test_batches]\n    \n    train_ds = train_ds.repeat(num_epochs)\n    \n    dataset_lengths = (len(train_ds), 0, len(test_ds))\n    \n    return train_ds, None, test_ds, dataset_lengths\n\nprint(\"✓ Data loader defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:32:38.129365Z","iopub.execute_input":"2025-12-26T01:32:38.129635Z","iopub.status.idle":"2025-12-26T01:32:44.644895Z","shell.execute_reply.started":"2025-12-26T01:32:38.129616Z","shell.execute_reply":"2025-12-26T01:32:44.644050Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✓ Data loader defined\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Step 5: Download MBPP+ Dataset","metadata":{}},{"cell_type":"code","source":"import datasets\nprint(\"pyarrow.__version__\", pyarrow.__version__)\nprint(\"datasets.__version__\", datasets.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:32:46.047135Z","iopub.execute_input":"2025-12-26T01:32:46.047512Z","iopub.status.idle":"2025-12-26T01:32:46.050665Z","shell.execute_reply.started":"2025-12-26T01:32:46.047496Z","shell.execute_reply":"2025-12-26T01:32:46.049957Z"}},"outputs":[{"name":"stdout","text":"pyarrow.__version__ 22.0.0\ndatasets.__version__ 4.4.2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%time\nimport os\nfrom datasets import load_dataset\n\nprint(pyarrow.__version__)\nprint(\"Downloading MBPP+ dataset...\")\nos.makedirs(\"./data/mbppplus_hf\", exist_ok=True)\ndataset = load_dataset(\"evalplus/mbppplus\", split=\"test\")\ndataset.to_parquet(\"./data/mbppplus_hf/test.parquet\")\nprint(f\"✓ Downloaded {len(dataset)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:32:50.393408Z","iopub.execute_input":"2025-12-26T01:32:50.393683Z","iopub.status.idle":"2025-12-26T01:32:53.538230Z","shell.execute_reply.started":"2025-12-26T01:32:50.393666Z","shell.execute_reply":"2025-12-26T01:32:53.537475Z"}},"outputs":[{"name":"stdout","text":"22.0.0\nDownloading MBPP+ dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/518 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b17e15c23b840268643bf3e363fe93f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001-d5781c9c51e0279(…):   0%|          | 0.00/1.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f4e0f2fba4d474b8ab041679f6d5292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/378 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2721c675c12b48c09a8a4d2aac776a35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ca0c23c536c41eb811b823eccfca25b"}},"metadata":{}},{"name":"stdout","text":"✓ Downloaded 378 samples\nCPU times: user 404 ms, sys: 123 ms, total: 527 ms\nWall time: 3.14 s\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Step 6: Import Libraries and Setup","metadata":{}},{"cell_type":"code","source":"import jax\nfrom flax import nnx\nimport optax\nfrom huggingface_hub import snapshot_download\n\nfrom tunix.rl import rl_cluster as rl_cluster_lib\nfrom tunix.rl.grpo.grpo_learner import GRPOConfig, GRPOLearner\nfrom tunix.models.gemma3 import model as gemma_lib\nfrom tunix.models.gemma3 import params_safetensors as params_safetensors_lib\nfrom tunix.rl.rollout import base_rollout\nfrom tunix.generate import tokenizer_adapter as tokenizer_lib\n\nprint(\"✓ All libraries imported\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:33:00.316079Z","iopub.execute_input":"2025-12-26T01:33:00.316659Z","iopub.status.idle":"2025-12-26T01:33:01.885265Z","shell.execute_reply.started":"2025-12-26T01:33:00.316642Z","shell.execute_reply":"2025-12-26T01:33:01.884431Z"}},"outputs":[{"name":"stdout","text":"✓ All libraries imported\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Step 7: Setup TPU Mesh","metadata":{}},{"cell_type":"code","source":"NUM_TPUS = len(jax.devices())\nprint(NUM_TPUS)\nMESH_COUNTS = (2, 4) \nMESH = [MESH_COUNTS, (\"fsdp\", \"tp\")]\n\n\ndevice_type = devices[0].platform\nnum_devices = len(devices)\n\nprint(f\"Device type: {device_type}\")\nprint(f\"Number of devices: {num_devices}\")\n\nimport numpy as np\nif num_devices == 8:\n    print(\"Using 2D mesh: (1, 8)\")\n    devices_2d = np.array(devices).reshape(1, 8)\n    mesh = jax.make_mesh(\n        *MESH,\n        axis_types=(jax.sharding.AxisType.Auto,) * len(MESH_COUNTS),\n    )\nelif num_devices == 1:\n    print(\"Using 2D mesh: (1, 1)\")\n    devices_2d = np.array(devices).reshape(1, 1)\n    mesh = jax.sharding.Mesh(devices_2d, axis_names=('fsdp', 'tp'))\nelse:\n    raise ValueError(f\"Unsupported device count: {num_devices}\")\n\nprint(f\"✓ Mesh created: {mesh}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:51:45.110716Z","iopub.execute_input":"2025-12-26T01:51:45.110977Z","iopub.status.idle":"2025-12-26T01:51:45.117049Z","shell.execute_reply.started":"2025-12-26T01:51:45.110948Z","shell.execute_reply":"2025-12-26T01:51:45.115959Z"}},"outputs":[{"name":"stdout","text":"8\nDevice type: tpu\nNumber of devices: 8\nUsing 2D mesh: (1, 8)\n✓ Mesh created: Mesh('fsdp': 2, 'tp': 4, axis_types=(Auto, Auto))\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Step 8: Load Dataset (10 samples)","metadata":{}},{"cell_type":"code","source":"%%time\nprint(\"Loading 10 MBPP+ samples...\")\ntrain_dataset, val_dataset, test_dataset, dataset_lengths = get_mbpp_dataset(\n    local_path=\"./data/mbppplus_hf\",\n    train_fraction=1.0,\n    batch_size=1,\n    num_train_batches=10,\n    num_test_batches=2,\n    num_epochs=1,\n    shuffle=False,\n)\nprint(f\"✓ Loaded {dataset_lengths[0]} training batches\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:51:48.562345Z","iopub.execute_input":"2025-12-26T01:51:48.562645Z","iopub.status.idle":"2025-12-26T01:51:48.579596Z","shell.execute_reply.started":"2025-12-26T01:51:48.562624Z","shell.execute_reply":"2025-12-26T01:51:48.578650Z"}},"outputs":[{"name":"stdout","text":"Loading 10 MBPP+ samples...\n✓ Loaded 10 training batches\nCPU times: user 14.4 ms, sys: 936 μs, total: 15.4 ms\nWall time: 12.9 ms\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Step 9: Load Gemma-3-1B Model","metadata":{}},{"cell_type":"code","source":"from getpass import getpass\ntoken = getpass(\"Enter your Hugging Face token (will not be shown): \")\nos.environ[\"HF_TOKEN\"] = token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:49:50.722217Z","iopub.execute_input":"2025-12-26T01:49:50.722479Z","iopub.status.idle":"2025-12-26T01:49:50.726840Z","shell.execute_reply.started":"2025-12-26T01:49:50.722458Z","shell.execute_reply":"2025-12-26T01:49:50.725447Z"}},"outputs":[{"name":"stdout","text":"8\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%%time\nimport copy \n\nfrom huggingface_hub import snapshot_download\n\n\nprint(\"Loading Gemma-3-1B model...\")\nmodel_config = gemma_lib.ModelConfig.gemma3_1b_it()\n\n# Download model\nprint(\"  Downloading from Hugging Face...\")\nlocal_model_path = snapshot_download(\n    repo_id=MODEL_ID,\n    ignore_patterns=[\"*.pth\"],\n    token=token\n)\nprint(f\"  Model at: {local_model_path}\")\n\n# Create model\nprint(\"  Creating model on mesh...\")\nwith mesh:\n    actor_model = params_safetensors_lib.create_model_from_safe_tensors(\n        local_model_path, model_config, mesh\n    )\n    ref_model = copy.deepcopy(actor_model)\n\nfor p in ref_model.parameters():\n    p.requires_grad = False\nprint(\"✓ Model loaded\")\n\n# Create tokenizer\ntokenizer = tokenizer_lib.Tokenizer(\n    tokenizer_path=TOKENIZER_PATH,\n    tokenizer_type='sentencepiece'\n)\nprint(\"✓ Tokenizer loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:52:17.290481Z","iopub.execute_input":"2025-12-26T01:52:17.290805Z","iopub.status.idle":"2025-12-26T01:52:42.607175Z","shell.execute_reply.started":"2025-12-26T01:52:17.290785Z","shell.execute_reply":"2025-12-26T01:52:42.606014Z"}},"outputs":[{"name":"stdout","text":"Loading Gemma-3-1B model...\n  Downloading from Hugging Face...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (incomplete total...): 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5004e3926e4e4e46b3a26b580fa063c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adf482f32edb4c19b96c7ff860f7d7b7"}},"metadata":{}},{"name":"stdout","text":"  Model at: /root/.cache/huggingface/hub/models--google--gemma-3-1b-it/snapshots/dcc83ea841ab6100d6b47a070329e1ba4cf78752\n  Creating model on mesh...\n✓ Model loaded\n✓ Tokenizer loaded\nCPU times: user 19.8 s, sys: 2.84 s, total: 22.6 s\nWall time: 25.3 s\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Step 10: Create RL Cluster","metadata":{}},{"cell_type":"code","source":"optimizer = optax.adamw(learning_rate=LEARNING_RATE)\ncluster_config = rl_cluster_lib.ClusterConfig(\n    role_to_mesh={\n        rl_cluster_lib.Role.ACTOR: mesh,\n        rl_cluster_lib.Role.REFERENCE: mesh,\n        rl_cluster_lib.Role.ROLLOUT: mesh,\n    },\n    rollout_engine='vanilla',\n    offload_to_cpu=False,\n    training_config=rl_cluster_lib.RLTrainingConfig(\n        actor_optimizer=optimizer,\n        eval_every_n_steps=10,\n        max_steps=10,\n        mini_batch_size=1,\n        train_micro_batch_size=1,\n    ),\n    rollout_config=base_rollout.RolloutConfig(\n        max_tokens_to_generate=TOTAL_GENERATION_STEPS,\n        max_prompt_length=MAX_PROMPT_LENGTH,\n        kv_cache_size=MAX_SEQ_LEN,\n        temperature=TEMPERATURE,\n        top_k=TOP_K,\n        top_p=TOP_P,\n    ),\n)\n\nrl_cluster = rl_cluster_lib.RLCluster(\n    actor=actor_model,\n    reference=ref_model,\n    tokenizer=tokenizer,\n    cluster_config=cluster_config,\n)\nprint(\"✓ RL Cluster created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 11: Run GRPO Training","metadata":{}},{"cell_type":"code","source":"%%time\nprint(\"Creating GRPO trainer...\")\ngrpo_config = GRPOConfig(\n    num_generations=NUM_GENERATIONS,\n    beta=BETA,\n    epsilon=EPSILON,\n    num_iterations=NUM_ITERATIONS,\n)\n\ngrpo_trainer = GRPOLearner(\n    rl_cluster=rl_cluster,\n    reward_fns=DEFAULT_REWARD_FNS_MBPP,\n    algo_config=grpo_config,\n)\nprint(f\"Config: {NUM_GENERATIONS} generations, beta={BETA}, epsilon={EPSILON}\")\nprint(f\"Reward functions: {len(DEFAULT_REWARD_FNS_MBPP)}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Starting GRPO training on 10 samples...\")\nprint(\"=\" * 80)\n\ngrpo_trainer.train(\n    train_ds=train_dataset,\n    eval_ds=test_dataset,\n)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"✅ Training completed successfully!\")\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T01:52:48.027333Z","iopub.execute_input":"2025-12-26T01:52:48.027590Z","iopub.status.idle":"2025-12-26T01:54:55.395172Z","shell.execute_reply.started":"2025-12-26T01:52:48.027573Z","shell.execute_reply":"2025-12-26T01:54:55.393808Z"}},"outputs":[{"name":"stdout","text":"Creating GRPO trainer...\nConfig: 2 generations, beta=0.08, epsilon=0.2\nReward functions: 2\n\n================================================================================\nStarting GRPO training on 10 samples...\n================================================================================\nCPU times: user 2min 7s, sys: 3.64 s, total: 2min 11s\nWall time: 2min 6s\n","output_type":"stream"},{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCreating GRPO trainer...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mgrpo_config = GRPOConfig(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    num_generations=NUM_GENERATIONS,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    beta=BETA,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    epsilon=EPSILON,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    num_iterations=NUM_ITERATIONS,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mgrpo_trainer = GRPOLearner(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    rl_cluster=rl_cluster,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    reward_fns=DEFAULT_REWARD_FNS_MBPP,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    algo_config=grpo_config,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConfig: \u001b[39;49m\u001b[38;5;132;43;01m{NUM_GENERATIONS}\u001b[39;49;00m\u001b[33;43m generations, beta=\u001b[39;49m\u001b[38;5;132;43;01m{BETA}\u001b[39;49;00m\u001b[33;43m, epsilon=\u001b[39;49m\u001b[38;5;132;43;01m{EPSILON}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReward functions: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mlen(DEFAULT_REWARD_FNS_MBPP)}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m + \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m * 80)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStarting GRPO training on 10 samples...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m * 80)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mgrpo_trainer.train(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    train_ds=train_dataset,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    eval_ds=test_dataset,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m + \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m * 80)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m✅ Training completed successfully!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m * 80)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2572\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2571\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2572\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/IPython/core/magics/execution.py:1447\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/IPython/core/magics/execution.py:1411\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1409\u001b[39m st = clock2()\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:21\u001b[39m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/grpo/grpo_learner.py:398\u001b[39m, in \u001b[36mGRPOLearner.train\u001b[39m\u001b[34m(self, train_ds, eval_ds, skip_jit)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[32m    352\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    353\u001b[39m     train_ds: Iterable[TrainingInputT],\n\u001b[32m    354\u001b[39m     eval_ds: Iterable[TrainingInputT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    355\u001b[39m     skip_jit: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    356\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    357\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"GRPO training loop.\u001b[39;00m\n\u001b[32m    358\u001b[39m \n\u001b[32m    359\u001b[39m \u001b[33;03m  Algorithm as below: extract from https://arxiv.org/abs/2402.03300 ::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m    skip_jit: Whether to skip JIT compilation of the training loop.\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_jit\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/rl_learner.py:606\u001b[39m, in \u001b[36mRLLearner.train\u001b[39m\u001b[34m(self, train_ds, eval_ds, skip_jit)\u001b[39m\n\u001b[32m    603\u001b[39m initial_steps = \u001b[38;5;28mself\u001b[39m._iter_steps\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rl_cluster.perf.span_group(\u001b[33m\"\u001b[39m\u001b[33mglobal_step\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_global_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m      \u001b[49m\u001b[43mfull_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmini_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m      \u001b[49m\u001b[43mservice_target_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m      \u001b[49m\u001b[43mgrad_acc_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m      \u001b[49m\u001b[43meval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m      \u001b[49m\u001b[43mskip_jit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.should_sync_weights:\n\u001b[32m    617\u001b[39m     logging.debug(\n\u001b[32m    618\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSyncing weights at global step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    619\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.rl_cluster.global_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m mini batch step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    620\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._iter_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    621\u001b[39m     )\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/rl_learner.py:663\u001b[39m, in \u001b[36mRLLearner._run_global_step\u001b[39m\u001b[34m(self, full_batch_size, mini_batch_size, service_target_batch_size, grad_acc_steps, train_iterator, eval_ds, skip_jit)\u001b[39m\n\u001b[32m    660\u001b[39m initial_steps = \u001b[38;5;28mself\u001b[39m._iter_steps\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rl_cluster.perf.span_group(\u001b[33m\"\u001b[39m\u001b[33mmini_batch_step\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_mini_batch_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m      \u001b[49m\u001b[43minitial_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m      \u001b[49m\u001b[43mservice_target_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m      \u001b[49m\u001b[43mgrad_acc_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m      \u001b[49m\u001b[43meval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m      \u001b[49m\u001b[43mskip_jit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# sync the iter steps with internel trainer, this is based on the\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;66;03m# assumption that the trainer internally doesn't reset the iter steps.\u001b[39;00m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# there is current a unit test to ensure this assumption.\u001b[39;00m\n\u001b[32m    675\u001b[39m \u001b[38;5;28mself\u001b[39m._iter_steps = \u001b[38;5;28mself\u001b[39m.rl_cluster.actor_trainer.iter_steps\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/rl_learner.py:688\u001b[39m, in \u001b[36mRLLearner._run_mini_batch_step\u001b[39m\u001b[34m(self, initial_steps, service_target_batch_size, grad_acc_steps, train_iterator, eval_ds, skip_jit)\u001b[39m\n\u001b[32m    686\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run one mini batch step.\"\"\"\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rl_cluster.perf.span_group(\u001b[33m\"\u001b[39m\u001b[33mmicro_batch_steps\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_all_micro_batch_steps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m      \u001b[49m\u001b[43minitial_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mservice_target_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m      \u001b[49m\u001b[43mgrad_acc_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m      \u001b[49m\u001b[43meval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m      \u001b[49m\u001b[43mskip_jit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/rl_learner.py:780\u001b[39m, in \u001b[36mRLLearner._run_all_micro_batch_steps\u001b[39m\u001b[34m(self, initial_steps, service_target_batch_size, grad_acc_steps, train_iterator, eval_ds, skip_jit)\u001b[39m\n\u001b[32m    773\u001b[39m       \u001b[38;5;28mself\u001b[39m.rl_cluster.update_critic(\n\u001b[32m    774\u001b[39m           curr_train_ds,\n\u001b[32m    775\u001b[39m           curr_eval_ds,\n\u001b[32m    776\u001b[39m           skip_jit,\n\u001b[32m    777\u001b[39m       )  \u001b[38;5;66;03m# loop over μ num_iterations\u001b[39;00m\n\u001b[32m    779\u001b[39m \u001b[38;5;66;03m# call to throw stop iteration as a signal to break the loop\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/rl_learner.py:499\u001b[39m, in \u001b[36mRLLearner._prepare_data\u001b[39m\u001b[34m(self, iterator, proceed_num_steps, sample_repeat, batch_repeat, service_target_batch_size, data_queue, async_loading, mode)\u001b[39m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    501\u001b[39m   \u001b[38;5;66;03m# Signal no more iterable to be loaded.\u001b[39;00m\n\u001b[32m    502\u001b[39m   data_queue.put(\u001b[38;5;28;01mNone\u001b[39;00m)\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/rl_learner.py:465\u001b[39m, in \u001b[36mRLLearner._prepare_data\u001b[39m\u001b[34m(self, iterator, proceed_num_steps, sample_repeat, batch_repeat, service_target_batch_size, data_queue, async_loading, mode)\u001b[39m\n\u001b[32m    463\u001b[39m produced_training_examples = []\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m accumulated_samples_num >= service_target_batch_size:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m   produced_training_examples = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_accumulated_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmicro_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmicro_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmicro_batch_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmicro_batch_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m   micro_batches.clear()\n\u001b[32m    471\u001b[39m   micro_batch_sizes.clear()\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/rl_learner.py:270\u001b[39m, in \u001b[36mRLLearner._process_accumulated_batches\u001b[39m\u001b[34m(self, micro_batches, micro_batch_sizes, mode)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;66;03m# Merge multiple training micro-batches\u001b[39;00m\n\u001b[32m    268\u001b[39m merged = rl_utils.merge_micro_batches(micro_batches)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m combined_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_and_compute_advantage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# Split back to original training micro size\u001b[39;00m\n\u001b[32m    273\u001b[39m produced: \u001b[38;5;28mlist\u001b[39m[common.TrainExample] = []\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tunix/rl/grpo/grpo_learner.py:227\u001b[39m, in \u001b[36mGRPOLearner._generate_and_compute_advantage\u001b[39m\u001b[34m(self, training_input, mode)\u001b[39m\n\u001b[32m    224\u001b[39m completion_mask = completion_mask * completion_padding_mask\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.algo_config.beta != \u001b[32m0.0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m   devices = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrl_cluster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mr2m\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl_cluster_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRole\u001b[49m\u001b[43m.\u001b[49m\u001b[43mREFERENCE\u001b[49m\u001b[43m]\u001b[49m.devices\n\u001b[32m    228\u001b[39m   \u001b[38;5;66;03m# TODO(yangmu): use function decorator to trace this part, same below.\u001b[39;00m\n\u001b[32m    229\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rl_cluster.perf.span(\u001b[33m\"\u001b[39m\u001b[33mrefer_inference\u001b[39m\u001b[33m\"\u001b[39m, devices) \u001b[38;5;28;01mas\u001b[39;00m interval:\n","\u001b[31mKeyError\u001b[39m: <Role.REFERENCE: 'reference'>"],"ename":"KeyError","evalue":"<Role.REFERENCE: 'reference'>","output_type":"error"}],"execution_count":21}]}