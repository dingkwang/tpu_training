{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[],"dockerImageVersionId":31235,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MBPP+ GRPO Training on Kaggle TPU\nTrain Gemma-3-1B on MBPP+ code generation with 10 samples using GRPO.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Download MBPP+ Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport subprocess\n\nprint(\"=\" * 80)\nprint(\"MBPP+ GRPO Training - 10 Samples\")\nprint(\"=\" * 80)\n\nprint(\"\\n[1/7] Downloading MBPP+ dataset...\")\n\n!pip install -q \"pyarrow==20.0.0\" \"datasets>=3.0.0\"\n\n# Download dataset\nfrom datasets import load_dataset\nprint(\"  Downloading evalplus/mbppplus...\")\nos.makedirs(\"./data/mbppplus_hf\", exist_ok=True)\ndataset = load_dataset(\"evalplus/mbppplus\", split=\"test\")\ndataset.to_parquet(\"./data/mbppplus_hf/test.parquet\")\nprint(f\"  ✓ Downloaded {len(dataset)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T00:37:31.270538Z","iopub.execute_input":"2025-12-26T00:37:31.270856Z","iopub.status.idle":"2025-12-26T00:37:36.276886Z","shell.execute_reply.started":"2025-12-26T00:37:31.270833Z","shell.execute_reply":"2025-12-26T00:37:36.275631Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nMBPP+ GRPO Training - 10 Samples\n================================================================================\n\n[1/7] Downloading MBPP+ dataset...\n\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/usr/local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/usr/local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/usr/local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/usr/local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/usr/local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/usr/local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"},{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install -q \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpyarrow==20.0.0\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdatasets>=3.0.0\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Download dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Downloading evalplus/mbppplus...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33m./data/mbppplus_hf\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/datasets/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m4.0.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Column, Dataset\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/datasets/arrow_dataset.py:76\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_writer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_files\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownload\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstreaming_download_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m xgetsize\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/datasets/arrow_writer.py:28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m url_to_fs\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio, Features, Image, Pdf, Value, Video\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     FeatureType,\n\u001b[32m     31\u001b[39m     List,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     to_pyarrow_listarray,\n\u001b[32m     40\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfilesystems\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_remote_filesystem\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/datasets/features/__init__.py:20\u001b[39m\n\u001b[32m      1\u001b[39m __all__ = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAudio\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mArray2D\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPdf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Array2D, Array3D, Array4D, Array5D, ClassLabel, Features, LargeList, List, Sequence, Value\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pdf\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/datasets/features/features.py:45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, encode_pil_image\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pdf, encode_pdfplumber_pdf\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtranslation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Translation, TranslationVariableLanguages\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvideo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Video\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/datasets/features/pdf.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownload\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownload_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_cast\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_local_path, xopen\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpy_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m no_op_if_value_is_null, string_to_dict\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n","\u001b[31mImportError\u001b[39m: cannot import name 'xopen' from 'datasets.utils.file_utils' (/usr/local/lib/python3.12/site-packages/datasets/utils/file_utils.py)"],"ename":"ImportError","evalue":"cannot import name 'xopen' from 'datasets.utils.file_utils' (/usr/local/lib/python3.12/site-packages/datasets/utils/file_utils.py)","output_type":"error"}],"execution_count":5},{"cell_type":"markdown","source":"## Step 2: Install tunix Library","metadata":{}},{"cell_type":"code","source":"!pip install -q -U \"google-tunix[prod]\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T00:34:31.627919Z","iopub.execute_input":"2025-12-26T00:34:31.628218Z","iopub.status.idle":"2025-12-26T00:37:25.492479Z","shell.execute_reply.started":"2025-12-26T00:34:31.628188Z","shell.execute_reply":"2025-12-26T00:37:25.491121Z"}},"outputs":[{"name":"stdout","text":"Username for 'https://github.com': ^C\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Step 3: Import Libraries and Helper Modules","metadata":{}},{"cell_type":"code","source":"print(\"\\n[3/7] Importing libraries...\")\nimport jax\nfrom flax import nnx\nimport optax\n\nfrom tunix.rl import rl_cluster as rl_cluster_lib\nfrom tunix.rl.grpo.grpo_learner import GRPOConfig, GRPOLearner\nfrom tunix.models.gemma3 import model as gemma_lib\nfrom tunix.models.gemma3 import params_safetensors as params_safetensors_lib\nfrom tunix.rl.rollout import base_rollout\nfrom huggingface_hub import snapshot_download\n\n# Import helper modules (uploaded with notebook)\nfrom mbpp_data_loader import get_mbpp_dataset\nfrom reward_functions_mbpp import DEFAULT_REWARD_FNS_MBPP\nfrom config import *\n\nprint(\"  ✓ All libraries imported\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Setup TPU Mesh","metadata":{}},{"cell_type":"code","source":"print(\"\\n[4/7] Setting up TPU mesh...\")\ndevices = jax.devices()\ndevice_type = devices[0].platform\nnum_devices = len(devices)\nprint(f\"  Device type: {device_type}\")\nprint(f\"  Number of devices: {num_devices}\")\n\nif num_devices == 8:\n    # TPU v3-8: reshape to 2D (1, 8)\n    print(f\"  Using 2D mesh: (1, 8)\")\n    import numpy as np\n    devices_2d = np.array(devices).reshape(1, 8)\n    mesh = jax.sharding.Mesh(\n        devices_2d,\n        axis_names=('fsdp', 'tp')\n    )\nelif num_devices == 1:\n    # Single device: use 2D mesh (1, 1)\n    print(f\"  Using 2D mesh (1, 1) for single device\")\n    import numpy as np\n    devices_2d = np.array(devices).reshape(1, 1)\n    mesh = jax.sharding.Mesh(\n        devices_2d,\n        axis_names=('fsdp', 'tp')\n    )\nelse:\n    # Use config.MESH\n    mesh = jax.make_mesh(\n        *MESH,\n        axis_types=(jax.sharding.AxisType.Auto,) * len(MESH[0])\n    )\n\nprint(f\"  ✓ Mesh created: {mesh}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Load MBPP+ Dataset (10 samples)","metadata":{}},{"cell_type":"code","source":"print(\"\\n[5/7] Loading 10 MBPP+ samples...\")\ntrain_dataset, val_dataset, test_dataset, dataset_lengths = get_mbpp_dataset(\n    local_path=\"./data/mbppplus_hf\",\n    train_fraction=1.0,\n    batch_size=1,\n    num_train_batches=10,\n    num_test_batches=2,\n    num_epochs=1,\n    shuffle=False,\n)\nprint(f\"  ✓ Loaded {dataset_lengths[0]} training batches\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Load Gemma-3-1B Model","metadata":{}},{"cell_type":"code","source":"print(\"\\n[6/7] Loading Gemma-3-1B model...\")\nmodel_config = gemma_lib.ModelConfig.gemma3_1b_it()\n\n# Download model\nprint(\"  Downloading from Hugging Face...\")\nlocal_model_path = snapshot_download(\n    repo_id=MODEL_ID,\n    ignore_patterns=[\"*.pth\"]\n)\nprint(f\"  Model at: {local_model_path}\")\n\n# Create model from safetensors\nprint(\"  Creating model on TPU mesh...\")\nwith mesh:\n    actor_model = params_safetensors_lib.create_model_from_safe_tensors(\n        local_model_path, model_config, mesh\n    )\nprint(\"  ✓ Model loaded\")\n\n# Create tokenizer\nfrom tunix.generate import tokenizer_adapter as tokenizer_lib\ntokenizer = tokenizer_lib.Tokenizer(\n    tokenizer_path=TOKENIZER_PATH,\n    tokenizer_type='sentencepiece'\n)\nprint(\"  ✓ Tokenizer loaded\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6b: Create RL Cluster","metadata":{}},{"cell_type":"code","source":"# Create optimizer and cluster config\noptimizer = optax.adamw(learning_rate=LEARNING_RATE)\ncluster_config = rl_cluster_lib.ClusterConfig(\n    role_to_mesh={\n        rl_cluster_lib.Role.ACTOR: mesh,\n        rl_cluster_lib.Role.ROLLOUT: mesh,\n    },\n    rollout_engine='vanilla',\n    offload_to_cpu=False,\n    training_config=rl_cluster_lib.RLTrainingConfig(\n        actor_optimizer=optimizer,\n        eval_every_n_steps=10,\n        max_steps=10,\n        mini_batch_size=1,\n        train_micro_batch_size=1,\n    ),\n    rollout_config=base_rollout.RolloutConfig(\n        max_tokens_to_generate=TOTAL_GENERATION_STEPS,\n        max_prompt_length=MAX_PROMPT_LENGTH,\n        kv_cache_size=MAX_SEQ_LEN,\n        temperature=TEMPERATURE,\n        top_k=TOP_K,\n        top_p=TOP_P,\n    ),\n)\n\n# Create RL cluster\nrl_cluster = rl_cluster_lib.RLCluster(\n    actor=actor_model,\n    tokenizer=tokenizer,\n    cluster_config=cluster_config,\n)\nprint(\"  ✓ RL Cluster created\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7: Run GRPO Training","metadata":{}},{"cell_type":"code","source":"print(\"\\n[7/7] Running GRPO training on 10 samples...\")\ngrpo_config = GRPOConfig(\n    num_generations=NUM_GENERATIONS,\n    beta=BETA,\n    epsilon=EPSILON,\n    num_iterations=NUM_ITERATIONS,\n)\n\ngrpo_trainer = GRPOLearner(\n    rl_cluster=rl_cluster,\n    reward_fns=DEFAULT_REWARD_FNS_MBPP,\n    algo_config=grpo_config,\n)\nprint(f\"  Config: {NUM_GENERATIONS} generations, beta={BETA}, epsilon={EPSILON}\")\nprint(f\"  Reward functions: {len(DEFAULT_REWARD_FNS_MBPP)}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Starting training...\")\nprint(\"=\" * 80)\n\ntry:\n    grpo_trainer.train(\n        train_ds=train_dataset,\n        eval_ds=test_dataset,\n    )\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"✅ Training completed successfully!\")\n    print(\"=\" * 80)\n\nexcept Exception as e:\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"❌ Training failed: {e}\")\n    print(\"=\" * 80)\n    import traceback\n    traceback.print_exc()\n    raise","metadata":{},"outputs":[],"execution_count":null}]}